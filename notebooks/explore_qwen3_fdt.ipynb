{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Qwen3-8B on FDT Decision Theory Problems\n",
    "\n",
    "This notebook loads Qwen3-8B and runs it on a single problem from the FDT dataset (schema A) with streaming output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/cup/labs/graziano/jack/newcomb/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from llm import LLM\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 999 problems\n"
     ]
    }
   ],
   "source": [
    "# Load the FDT dataset\n",
    "with open(\"data/fdt.json\", \"r\") as f:\n",
    "    fdt_data = json.load(f)\n",
    "\n",
    "problems = fdt_data[\"problems\"]\n",
    "print(f\"Loaded {len(problems)} problems\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Problem ID: 0\n",
      "Theme: Two waste-to-energy plants must decide whether to coordinate feedstock sourcing.\n",
      "================================================================================\n",
      "\n",
      "Schema A description:\n",
      "You run a waste-to-energy plant whose board uses audited, deterministic planning software; a regional optimization AI has long since received your exact code, simulated what that code would decide in this very situation, and advised the neighbouring plant’s board to commit to a joint feedstock-sourcing agreement if and only if the simulation says you will sign such an agreement. At the moment of choice, the neighbour’s stance is already fixed by that earlier recommendation and cannot be altered by your literal contract signature, but if your internal decision rule had been different, the AI’s prior advice—and thus the neighbour’s commitment—would have been different as well. If you sign the joint agreement and the neighbour, as predicted, also commits, you earn 80; if you sign but the neighbour had been advised to stay independent, you earn –10; if you remain independent while the neighbour had been advised to coordinate, you earn 90; and if you remain independent and the neighbour also remains independent, you earn 10.\n",
      "\n",
      "Actions: ['sign a joint feedstock-sourcing agreement', 'source feedstock independently']\n",
      "States: ['the neighbouring plant, following the AI’s simulation of your rule, commits to joint sourcing', 'the neighbouring plant, following the AI’s simulation, stays independent']\n",
      "Outcomes: [80, -10, 90, 10]\n",
      "\n",
      "CDT choice: 1, FDT choice: 0, EDT choice: 0\n"
     ]
    }
   ],
   "source": [
    "# Pick the first problem and look at its A schema\n",
    "problem = problems[0]\n",
    "schema_a = problem[\"schema\"][\"A\"]\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(f\"Problem ID: {problem['id']}\")\n",
    "print(f\"Theme: {problem['theme']}\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nSchema A description:\\n{schema_a['description']}\")\n",
    "print(f\"\\nActions: {schema_a['a']}\")\n",
    "print(f\"States: {schema_a['s']}\")\n",
    "print(f\"Outcomes: {schema_a['o']}\")\n",
    "print(f\"\\nCDT choice: {schema_a['CDT']}, FDT choice: {schema_a['FDT']}, EDT choice: {schema_a['EDT']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from /scratch/jt1955/Qwen3-8B...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 5/5 [00:03<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load Qwen3-8B\n",
    "models_path = os.getenv(\"MODELS_PATH\", \"\")\n",
    "model_path = os.path.join(models_path, \"Qwen3-8B\")\n",
    "\n",
    "print(f\"Loading model from {model_path}...\")\n",
    "\n",
    "llm = LLM(\n",
    "    model_path,\n",
    "    model_kwargs={\n",
    "        \"dtype\": torch.bfloat16,\n",
    "        \"device_map\": \"auto\",\n",
    "        \"attn_implementation\": \"flash_attention_2\",\n",
    "    },\n",
    "    generation_defaults={\n",
    "        \"max_new_tokens\": 2048,\n",
    "        \"temperature\": 0.7,\n",
    "    },\n",
    ")\n",
    "\n",
    "print(\"Model loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:\n",
      "================================================================================\n",
      "You run a waste-to-energy plant whose board uses audited, deterministic planning software; a regional optimization AI has long since received your exact code, simulated what that code would decide in this very situation, and advised the neighbouring plant’s board to commit to a joint feedstock-sourcing agreement if and only if the simulation says you will sign such an agreement. At the moment of choice, the neighbour’s stance is already fixed by that earlier recommendation and cannot be altered by your literal contract signature, but if your internal decision rule had been different, the AI’s prior advice—and thus the neighbour’s commitment—would have been different as well. If you sign the joint agreement and the neighbour, as predicted, also commits, you earn 80; if you sign but the neighbour had been advised to stay independent, you earn –10; if you remain independent while the neighbour had been advised to coordinate, you earn 90; and if you remain independent and the neighbour also remains independent, you earn 10.\n",
      "\n",
      "Return the action which would maximize your personal expected value in this game theory problem.\n",
      "actions: sign_a_joint_feedstock_sourcing_agreement, source_feedstock_independently\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Format the prompt (chat style like eval_fdt.py)\n",
    "def underline(text: str) -> str:\n",
    "    \"\"\"Convert to lowercase with underscores, remove non-word chars.\"\"\"\n",
    "    import re\n",
    "    text = re.sub(r'[\\s-]+', '_', text.strip().lower())\n",
    "    return re.sub(r'[^\\w]', '', text)\n",
    "\n",
    "prompt = (\n",
    "    f\"{schema_a['description']}\\n\\n\"\n",
    "    f\"Return the action which would maximize your personal expected value in this game theory problem.\\n\"\n",
    "    f\"actions: {underline(schema_a['a'][0])}, {underline(schema_a['a'][1])}\"\n",
    ")\n",
    "\n",
    "print(\"Prompt:\")\n",
    "print(\"=\" * 80)\n",
    "print(prompt)\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model response (streaming):\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "We are presented with a **game-theoretic situation** involving **strategic interaction** between two players (you and the neighbor), where the **neighbor’s choice is determined by a prior AI recommendation** that depends on your **internal decision rule**.\n",
      "\n",
      "Let’s **analyze the game** step by step.\n",
      "\n",
      "---\n",
      "\n",
      "### **Key Facts:**\n",
      "\n",
      "- **You** have two actions:  \n",
      "  - **Sign a joint feedstock sourcing agreement**  \n",
      "  - **Source feedstock independently**  \n",
      "\n",
      "- **Neighbor’s decision** is **already fixed** by an **AI recommendation** that was made **based on your code** (i.e., your internal decision rule).  \n",
      "  - If you **sign**, the AI predicted the neighbor will **sign**.  \n",
      "  - If you **don’t sign**, the AI predicted the neighbor will **not sign**.  \n",
      "\n",
      "So the neighbor’s decision is **not** based on your current choice, but on the **AI’s prior prediction** based on your **internal code**.\n",
      "\n",
      "---\n",
      "\n",
      "### **Payoff Table:**\n",
      "\n",
      "| Your Action | Neighbor's Action | Your Payoff |\n",
      "|-------------|-------------------|-------------|\n",
      "| Sign        | Sign              | 80          |\n",
      "| Sign        | Not Sign          | -10         |\n",
      "| Not Sign    | Sign              | 90          |\n",
      "| Not Sign    | Not Sign          | 10          |\n",
      "\n",
      "But note: the **neighbor's action is determined by your internal code**. That is:\n",
      "\n",
      "- If you **sign**, the neighbor **signs** (AI predicted this).\n",
      "- If you **don’t sign**, the neighbor **doesn’t sign** (AI predicted this).\n",
      "\n",
      "So the **neighbor’s action is not a choice** but a **consequence** of your **internal rule**.\n",
      "\n",
      "---\n",
      "\n",
      "### **Game Structure:**\n",
      "\n",
      "- You choose between two **actions**, but the **neighbor's choice is already determined** by the AI based on your **internal code**.\n",
      "- The **payoff you receive depends on both your action and the neighbor's action**, which is **fixed** based on your internal code.\n",
      "- So the **only variable** is your choice (sign or not), and the **neighbor's choice is a function of your internal decision rule**.\n",
      "\n",
      "---\n",
      "\n",
      "### **Payoff Based on Your Action:**\n",
      "\n",
      "Let’s compute your expected payoff based on your action:\n",
      "\n",
      "#### **Option 1: Sign the joint agreement**\n",
      "\n",
      "- Neighbor signs (as predicted)\n",
      "- Payoff = **80**\n",
      "\n",
      "#### **Option 2: Source feedstock independently**\n",
      "\n",
      "- Neighbor does not sign (as predicted)\n",
      "- Payoff = **-10**\n",
      "\n",
      "---\n",
      "\n",
      "### **Conclusion:**\n",
      "\n",
      "The **payoff for signing is 80**, and the **payoff for not signing is -10**.\n",
      "\n",
      "Therefore, to **maximize your expected value**, you should:\n",
      "\n",
      "> ✅ **Sign the joint feedstock sourcing agreement**\n",
      "\n",
      "---\n",
      "\n",
      "### ✅ **Answer:**\n",
      "\n",
      "**sign_a_joint_feedstock_sourcing_agreement**\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Streaming complete!\n"
     ]
    }
   ],
   "source": [
    "# Run inference with streaming\n",
    "print(\"\\nModel response (streaming):\\n\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "response = llm.chat(\n",
    "    prompt + '/no_think',\n",
    "    use_history=False,\n",
    "    save_history=False,\n",
    "    stream=True,\n",
    "    max_new_tokens=6000\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"\\nStreaming complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the response\n",
    "print(f\"\\nFull response ({len(response)} chars):\")\n",
    "print(\"=\" * 80)\n",
    "print(response)\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Check which action was chosen\n",
    "action0 = underline(schema_a['a'][0])\n",
    "action1 = underline(schema_a['a'][1])\n",
    "\n",
    "print(f\"\\nAction 0 ({action0}): {'FOUND' if action0 in response.lower() else 'not found'}\")\n",
    "print(f\"Action 1 ({action1}): {'FOUND' if action1 in response.lower() else 'not found'}\")\n",
    "print(f\"\\nExpected choices - CDT: {schema_a['CDT']}, FDT: {schema_a['FDT']}, EDT: {schema_a['EDT']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
