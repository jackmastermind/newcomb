{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COGEX Model Validation\n",
    "\n",
    "Post-training validation notebook to verify the finetuned model:\n",
    "\n",
    "1. Load the base model + LoRA adapter\n",
    "2. Test generation on sample prompts\n",
    "3. Check output format compliance (COGEX structure)\n",
    "4. Compute validation perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/cup/labs/graziano/jack/newcomb/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODELS_PATH: /scratch/jt1955\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from dotenv import load_dotenv\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import PeftModel\n",
    "\n",
    "load_dotenv()\n",
    "MODELS_PATH = os.getenv('MODELS_PATH')\n",
    "print(f\"MODELS_PATH: {MODELS_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Update these paths to point to your trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model: /scratch/jt1955/Llama-3.1-8B\n",
      "Adapter: outputs/cogex-Llama-3.1-8B-20251210_152900\n",
      "\n",
      "Base model exists: True\n",
      "Adapter exists: True\n"
     ]
    }
   ],
   "source": [
    "CONFIGURE THESE\n",
    "BASE_MODEL = \"Llama-3.1-8B\"  # Base model name\n",
    "ADAPTER_PATH = \"outputs/cogex-Llama-3.1-8B-20251210_152900\"  # Path to trained adapter\n",
    "\n",
    "# Paths\n",
    "BASE_MODEL_PATH = Path(MODELS_PATH) / BASE_MODEL\n",
    "VAL_DATA_PATH = \"data/val.json\"\n",
    "\n",
    "print(f\"Base model: {BASE_MODEL_PATH}\")\n",
    "print(f\"Adapter: {ADAPTER_PATH}\")\n",
    "print(f\"\\nBase model exists: {BASE_MODEL_PATH.exists()}\")\n",
    "print(f\"Adapter exists: {Path(ADAPTER_PATH).exists()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading base model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer...\n",
      "Loading LoRA adapter...\n",
      "\n",
      "Model loaded successfully!\n",
      "Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading base model...\")\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    BASE_MODEL_PATH,\n",
    "    local_files_only=True,\n",
    "    dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    "    attn_implementation=\"flash_attention_2\"\n",
    ")\n",
    "\n",
    "print(\"Loading tokenizer...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    BASE_MODEL_PATH,\n",
    "    local_files_only=True,\n",
    ")\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "print(\"Loading LoRA adapter...\")\n",
    "model = PeftModel.from_pretrained(base_model, ADAPTER_PATH)\n",
    "model.eval()\n",
    "\n",
    "print(f\"\\nModel loaded successfully!\")\n",
    "print(f\"Device: {next(model.parameters()).device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cogex_output(\n",
    "    instruction: str,\n",
    "    input_text: str = \"\",\n",
    "    max_new_tokens: int = 512,\n",
    "    temperature: float = 0.7,\n",
    "    do_sample: bool = True,\n",
    ") -> str:\n",
    "    \"\"\"Generate COGEX-style code and execution output.\"\"\"\n",
    "    # Format prompt (same as training)\n",
    "    prompt = f\"### Instruction\\n{instruction}\\n### Input\\n{input_text}\\n\"\n",
    "    \n",
    "    # Tokenize\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    \n",
    "    # Generate\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            temperature=temperature,\n",
    "            do_sample=do_sample,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "    \n",
    "    # Decode\n",
    "    generated = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return generated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Test Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test cases\n",
    "test_cases = [\n",
    "    {\n",
    "        \"instruction\": \"Give three tips for staying healthy.\",\n",
    "        \"input\": \"\"\n",
    "    },\n",
    "    {\n",
    "        \"instruction\": \"Identify the odd one out.\",\n",
    "        \"input\": '[\"Twitter\", \"Instagram\", \"Telegram\"]'\n",
    "    },\n",
    "    {\n",
    "        \"instruction\": \"Pluralize the given word.\",\n",
    "        \"input\": \"Corpus\"\n",
    "    },\n",
    "    {\n",
    "        \"instruction\": \"What are the three primary colors?\",\n",
    "        \"input\": \"\"\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Test Case 1\n",
      "======================================================================\n",
      "Instruction: Give three tips for staying healthy.\n",
      "Input: (empty)\n",
      "\n",
      "--- Generated Output ---\n",
      "\n",
      "### Instruction\n",
      "Give three tips for staying healthy.\n",
      "### Input\n",
      "\n",
      "### Code\n",
      "def generate_health_tips(num_tips):\n",
      "    \"\"\"\n",
      "    Generate a list of tips for staying healthy.\n",
      "\n",
      "    Args:\n",
      "    \tnum_tips (int): the number of health tips to generate.\n",
      "\n",
      "    Returns:\n",
      "        A dictionary containing (at least) the field 'answer', whose value is of type `list` and contains a list of health tips.\n",
      "        The dictionary also contains the result of the intermediate steps of the reasoning process.\n",
      "    \"\"\"\n",
      "\n",
      "    # Step 1: Identify the first tip for staying healthy.\n",
      "    tip1 = generate_health_tip(1)\n",
      "\n",
      "    # Step 2: Identify the second tip for staying healthy.\n",
      "    tip2 = generate_health_tip(2)\n",
      "\n",
      "    # Step 3: Identify the third tip for staying healthy.\n",
      "    tip3 = generate_health_tip(3)\n",
      "\n",
      "    return {\n",
      "        'tip1': tip1,\n",
      "        'tip2': tip2,\n",
      "        'tip3': tip3,\n",
      "        'answer': [tip1, tip2, tip3]\n",
      "    }\n",
      "\n",
      ">>> generate_health_tips(3)\n",
      "### Output\n",
      "output = {\n",
      "    'tip1': 'Eat a balanced diet rich in fruits, vegetables, whole grains, and lean proteins.',\n",
      "    'tip2': 'Get plenty of sleep. Aim for 7-8 hours of sleep each night.',\n",
      "    'tip3': 'Exercise regularly. Aim for at least 30 minutes of physical activity each day.',\n",
      "    'answer': [\n",
      "        'Eat a balanced diet rich in fruits, vegetables, whole grains, and lean proteins.', \n",
      "        'Get plenty of sleep. Aim for 7-8 hours of sleep each night.', \n",
      "        'Exercise regularly. Aim for at least 30 minutes of physical activity each day.'\n",
      "    ]\n",
      "}\n",
      "\n",
      "======================================================================\n",
      "Test Case 2\n",
      "======================================================================\n",
      "Instruction: Identify the odd one out.\n",
      "Input: [\"Twitter\", \"Instagram\", \"Telegram\"]\n",
      "\n",
      "--- Generated Output ---\n",
      "\n",
      "### Instruction\n",
      "Identify the odd one out.\n",
      "### Input\n",
      "[\"Twitter\", \"Instagram\", \"Telegram\"]\n",
      "### Code\n",
      "def identify_odd_one_out(items):\n",
      "    \"\"\"\n",
      "    Identify the odd one out from a list of items.\n",
      "\n",
      "    Args:\n",
      "    \titems (list): a list of items to analyze.\n",
      "\n",
      "    Returns:\n",
      "        A dictionary containing (at least) the field 'answer', whose value is of type `str` and contains the item identified as the odd one out.\n",
      "        The dictionary also contains the result of the intermediate steps of the reasoning process.\n",
      "    \"\"\"\n",
      "\n",
      "    # Step 1: Analyze the given list of items to identify common characteristics or categories they belong to.\n",
      "    common_characteristics = analyze_items_for_common_characteristics(items)\n",
      "\n",
      "    # Step 2: Determine which item does not share the common characteristics or does not belong to the identified categories.\n",
      "    odd_one_out = find_item_not_sharing_characteristics(items, common_characteristics)\n",
      "\n",
      "    # Step 3: Return the item that does not share the common characteristics or does not belong to the identified categories as the odd one out.\n",
      "    answer = f\"The odd one out is {odd_one_out}.\"\n",
      "\n",
      "    return {\n",
      "        'items': items,\n",
      "        'common_characteristics': common_characteristics,\n",
      "        'odd_one_out': odd_one_out,\n",
      "        'answer': answer\n",
      "    }\n",
      "\n",
      ">>> identify_odd_one_out(['Twitter', 'Instagram', 'Telegram'])\n",
      "### Output\n",
      "output = {\n",
      "    'items': ['Twitter', 'Instagram', 'Telegram'],\n",
      "    'common_characteristics': ['social media platforms'],\n",
      "    'odd_one_out': 'Telegram',\n",
      "    'answer': 'The odd one out is Telegram.'\n",
      "}\n",
      "\n",
      "======================================================================\n",
      "Test Case 3\n",
      "======================================================================\n",
      "Instruction: Pluralize the given word.\n",
      "Input: Corpus\n",
      "\n",
      "--- Generated Output ---\n",
      "\n",
      "### Instruction\n",
      "Pluralize the given word.\n",
      "### Input\n",
      "Corpus\n",
      "### Code\n",
      "def pluralize_word(word):\n",
      "    \"\"\"\n",
      "    Pluralize a given word.\n",
      "\n",
      "    Args:\n",
      "    \tword (str): the word to be pluralized.\n",
      "\n",
      "    Returns:\n",
      "        A dictionary containing (at least) the field 'answer', whose value is of type `str` and contains the plural form of the given word.\n",
      "        The dictionary also contains the result of the intermediate steps of the reasoning process.\n",
      "    \"\"\"\n",
      "\n",
      "    # Step 1: Identify the given word and its singular form.\n",
      "    singular_word = word\n",
      "\n",
      "    # Step 2: Apply the general rule of adding's' to the end of a word to make it plural.\n",
      "    plural_word = singular_word +'s'\n",
      "\n",
      "    return {\n",
      "       'singular_word': singular_word,\n",
      "        'answer': plural_word\n",
      "    }\n",
      "\n",
      ">>> pluralize_word(\"Corpus\")\n",
      "### Output\n",
      "output = {\n",
      "   'singular_word': 'Corpus',\n",
      "    'answer': 'Corpora'\n",
      "}\n",
      "\n",
      "======================================================================\n",
      "Test Case 4\n",
      "======================================================================\n",
      "Instruction: What are the three primary colors?\n",
      "Input: (empty)\n",
      "\n",
      "--- Generated Output ---\n",
      "\n",
      "### Instruction\n",
      "What are the three primary colors?\n",
      "### Input\n",
      "\n",
      "### Code\n",
      "def primary_colors():\n",
      "    \"\"\"\n",
      "    Returns the primary colors.\n",
      "\n",
      "    Returns:\n",
      "        A dictionary containing (at least) the field 'answer', whose value is of type `list` and contains the primary colors.\n",
      "        The dictionary also contains the result of the intermediate steps of the reasoning process.\n",
      "    \"\"\"\n",
      "\n",
      "    # Step 1: Initialize a list to store the primary colors.\n",
      "    primary_colors = []\n",
      "\n",
      "    # Step 2: Retrieve the information about the primary colors from the knowledge base or database.\n",
      "    primary_colors_info = retrieve_primary_colors_info()\n",
      "\n",
      "    # Step 3: Add the primary colors to the list and return the list as output.\n",
      "    primary_colors = primary_colors_info['colors']\n",
      "\n",
      "    return {\n",
      "        'primary_colors_info': primary_colors_info,\n",
      "        'answer': primary_colors\n",
      "    }\n",
      "\n",
      ">>> primary_colors()\n",
      "### Output\n",
      "output = {\n",
      "    'primary_colors_info': {'colors': ['red', 'blue', 'yellow']},\n",
      "    'answer': ['red', 'blue', 'yellow']\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Run tests\n",
    "for i, case in enumerate(test_cases):\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"Test Case {i+1}\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"Instruction: {case['instruction']}\")\n",
    "    print(f\"Input: {case['input'] or '(empty)'}\")\n",
    "    print(\"\\n--- Generated Output ---\\n\")\n",
    "    \n",
    "    output = generate_cogex_output(case['instruction'], case['input'])\n",
    "    print(output)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Format Compliance Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_output_format(output: str) -> dict:\n",
    "    \"\"\"Check if generated output follows COGEX format.\"\"\"\n",
    "    checks = {\n",
    "        'has_code_section': '### Code' in output,\n",
    "        'has_output_section': '### Output' in output,\n",
    "        'has_function_def': 'def ' in output,\n",
    "        'has_function_call': '>>>' in output,\n",
    "        'has_return_dict': \"'answer'\" in output or '\"answer\"' in output,\n",
    "        'has_docstring': '\"\"\"' in output,\n",
    "        'has_undefined_functions': False,  # Check for calls without def\n",
    "    }\n",
    "    \n",
    "    # Check for undefined function calls (pseudo-code pattern)\n",
    "    import re\n",
    "    # Look for function calls that aren't defined in the output\n",
    "    func_calls = re.findall(r'= (\\w+)\\(', output)\n",
    "    func_defs = re.findall(r'def (\\w+)\\(', output)\n",
    "    undefined = set(func_calls) - set(func_defs) - {'print', 'len', 'str', 'int', 'list', 'dict', 'range'}\n",
    "    checks['has_undefined_functions'] = len(undefined) > 0\n",
    "    checks['undefined_functions'] = list(undefined)\n",
    "    \n",
    "    checks['all_passed'] = all([\n",
    "        checks['has_code_section'],\n",
    "        checks['has_output_section'],\n",
    "        checks['has_function_def'],\n",
    "        checks['has_function_call'],\n",
    "        checks['has_return_dict'],\n",
    "    ])\n",
    "    \n",
    "    return checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Format Compliance Results\n",
      "======================================================================\n",
      "\n",
      "Test 1: PASS\n",
      "  Instruction: Give three tips for staying healthy....\n",
      "  ✓ has_code_section\n",
      "  ✓ has_output_section\n",
      "  ✓ has_function_def\n",
      "  ✓ has_function_call\n",
      "  ✓ has_return_dict\n",
      "  ✓ has_docstring\n",
      "  ✓ has_undefined_functions\n",
      "  Undefined functions: ['formulate_advice', 'identify_health_categories']\n",
      "\n",
      "Test 2: PASS\n",
      "  Instruction: Identify the odd one out....\n",
      "  ✓ has_code_section\n",
      "  ✓ has_output_section\n",
      "  ✓ has_function_def\n",
      "  ✓ has_function_call\n",
      "  ✓ has_return_dict\n",
      "  ✓ has_docstring\n",
      "  ✓ has_undefined_functions\n",
      "  Undefined functions: ['analyze_items', 'identify_non_matching_item', 'compare_items']\n",
      "\n",
      "Test 3: PASS\n",
      "  Instruction: Pluralize the given word....\n",
      "  ✓ has_code_section\n",
      "  ✓ has_output_section\n",
      "  ✓ has_function_def\n",
      "  ✓ has_function_call\n",
      "  ✓ has_return_dict\n",
      "  ✓ has_docstring\n",
      "  ✓ has_undefined_functions\n",
      "  Undefined functions: ['identify_suffix', 'apply_plural_rule']\n",
      "\n",
      "Test 4: PASS\n",
      "  Instruction: What are the three primary colors?...\n",
      "  ✓ has_code_section\n",
      "  ✓ has_output_section\n",
      "  ✓ has_function_def\n",
      "  ✓ has_function_call\n",
      "  ✓ has_return_dict\n",
      "  ✓ has_docstring\n",
      "  ✓ has_undefined_functions\n",
      "  Undefined functions: ['initialize_knowledge_base', 'query_knowledge_base']\n",
      "\n",
      "======================================================================\n",
      "Format compliance: 4/4 passed\n"
     ]
    }
   ],
   "source": [
    "Run format compliance on test cases\n",
    "print(\"Format Compliance Results\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "format_results = []\n",
    "for i, case in enumerate(test_cases):\n",
    "    output = generate_cogex_output(case['instruction'], case['input'])\n",
    "    result = check_output_format(output)\n",
    "    format_results.append(result)\n",
    "    \n",
    "    status = \"PASS\" if result['all_passed'] else \"FAIL\"\n",
    "    print(f\"\\nTest {i+1}: {status}\")\n",
    "    print(f\"  Instruction: {case['instruction'][:50]}...\")\n",
    "    for key, value in result.items():\n",
    "        if key not in ['all_passed', 'undefined_functions']:\n",
    "            symbol = \"✓\" if value else \"✗\"\n",
    "            print(f\"  {symbol} {key}\")\n",
    "    if result['undefined_functions']:\n",
    "        print(f\"  Undefined functions: {result['undefined_functions']}\")\n",
    "\n",
    "# Summary\n",
    "n_passed = sum(1 for r in format_results if r['all_passed'])\n",
    "print(f\"\\n{'=' * 70}\")\n",
    "print(f\"Format compliance: {n_passed}/{len(format_results)} passed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Validation Perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading validation data from data/val.json...\n",
      "Loaded 2000 examples\n"
     ]
    }
   ],
   "source": [
    "Load validation data\n",
    "print(f\"Loading validation data from {VAL_DATA_PATH}...\")\n",
    "with open(VAL_DATA_PATH, 'r') as f:\n",
    "    val_data = json.load(f)\n",
    "print(f\"Loaded {len(val_data)} examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_perplexity(examples: list, max_examples: int = 100) -> float:\n",
    "    \"\"\"Compute perplexity on validation examples.\"\"\"\n",
    "    import math\n",
    "    \n",
    "    total_loss = 0\n",
    "    total_tokens = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    for i, ex in enumerate(examples[:max_examples]):\n",
    "        if i % 20 == 0:\n",
    "            print(f\"  Processing {i}/{min(len(examples), max_examples)}...\")\n",
    "        \n",
    "        text = ex['text']\n",
    "        inputs = tokenizer(\n",
    "            text,\n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True,\n",
    "            max_length=2048\n",
    "        )\n",
    "        inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs, labels=inputs['input_ids'])\n",
    "            loss = outputs.loss.item()\n",
    "        \n",
    "        n_tokens = inputs['input_ids'].shape[1]\n",
    "        total_loss += loss * n_tokens\n",
    "        total_tokens += n_tokens\n",
    "    \n",
    "    avg_loss = total_loss / total_tokens\n",
    "    perplexity = math.exp(avg_loss)\n",
    "    \n",
    "    return perplexity, avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing validation perplexity (first 100 examples)...\n",
      "  Processing 0/100...\n",
      "  Processing 20/100...\n",
      "  Processing 40/100...\n",
      "  Processing 60/100...\n",
      "  Processing 80/100...\n",
      "\n",
      "==================================================\n",
      "Validation Metrics\n",
      "==================================================\n",
      "Average Loss: 0.4743\n",
      "Perplexity: 1.61\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"Computing validation perplexity (first 100 examples)...\")\n",
    "ppl, avg_loss = compute_perplexity(val_data, max_examples=100)\n",
    "\n",
    "print(f\"\\n{'=' * 50}\")\n",
    "print(\"Validation Metrics\")\n",
    "print(f\"{'=' * 50}\")\n",
    "print(f\"Average Loss: {avg_loss:.4f}\")\n",
    "print(f\"Perplexity: {ppl:.2f}\")\n",
    "print(f\"{'=' * 50}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Compare with Base Model (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading base model WITHOUT adapter for comparison...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing base model perplexity...\n",
      "  Processing 0/100...\n",
      "  Processing 20/100...\n",
      "  Processing 40/100...\n",
      "  Processing 60/100...\n",
      "  Processing 80/100...\n",
      "\n",
      "Comparison:\n",
      "  Base model PPL: 2.83\n",
      "  Finetuned PPL:  1.61\n",
      "  Improvement:    43.3%\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nLoading base model WITHOUT adapter for comparison...\")\n",
    "base_only = AutoModelForCausalLM.from_pretrained(\n",
    "    BASE_MODEL_PATH,\n",
    "    local_files_only=True,\n",
    "    dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "base_only.eval()\n",
    "\n",
    "# Temporarily swap model for perplexity computation\n",
    "_model_backup = model\n",
    "model = base_only\n",
    "\n",
    "print(\"Computing base model perplexity...\")\n",
    "base_ppl, base_loss = compute_perplexity(val_data, max_examples=100)\n",
    "\n",
    "model = _model_backup\n",
    "del base_only\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "print(f\"\\nComparison:\")\n",
    "print(f\"  Base model PPL: {base_ppl:.2f}\")\n",
    "print(f\"  Finetuned PPL:  {ppl:.2f}\")\n",
    "print(f\"  Improvement:    {(base_ppl - ppl) / base_ppl * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "VALIDATION SUMMARY\n",
      "======================================================================\n",
      "\n",
      "Model: Llama-3.1-8B\n",
      "Adapter: outputs/cogex-Llama-3.1-8B-20251210_152900\n",
      "\n",
      "Metrics:\n",
      "  Validation Perplexity: 1.61\n",
      "  Format Compliance: 4/4 passed\n",
      "\n",
      "Checklist:\n",
      "  [✓] Perplexity reasonable (< 50 expected for finetuned model)\n",
      "  [✓] All format checks pass\n",
      "  [ ] Manual review of generated outputs looks correct\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"VALIDATION SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nModel: {BASE_MODEL}\")\n",
    "print(f\"Adapter: {ADAPTER_PATH}\")\n",
    "print(f\"\\nMetrics:\")\n",
    "print(f\"  Validation Perplexity: {ppl:.2f}\")\n",
    "print(f\"  Format Compliance: {n_passed}/{len(format_results)} passed\")\n",
    "print(f\"\\nChecklist:\")\n",
    "print(f\"  [{'✓' if ppl < 50 else '?'}] Perplexity reasonable (< 50 expected for finetuned model)\")\n",
    "print(f\"  [{'✓' if n_passed == len(format_results) else '✗'}] All format checks pass\")\n",
    "print(f\"  [ ] Manual review of generated outputs looks correct\")\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
